import pandas as pd
>>> c=pd.read_csv(r'C:\Users\Administrator\Desktop\jiu.csv')
>>> c
               a             b          c       d    e
0   1.378641e+10  6.465133e+10  5382382.0     NaN  NaN
1            NaN  6.542961e+10  5382382.0     NaN  NaN
2   1.558085e+10  6.545101e+10   565624.0     NaN  3.0
3            NaN  6.441465e+10   565624.0     NaN  3.0
4            NaN           NaN        NaN     NaN  NaN
5   1.814204e+10  6.458017e+10   394174.0   550.0  2.0
==============================================================================
>>> data=p.date_range('20171111',periods=3)
>>> data
DatetimeIndex(['2017-11-11', '2017-11-12', '2017-11-13'], dtype='datetime64[ns]', freq='D')
>>> d=p.DataFrame(data=np.random.randint(1,5,(3,4)),index=data)
>>> d
            0  1  2  3
2017-11-11  3  3  2  4
2017-11-12  2  1  2  4
2017-11-13  1  1  3  1
=================================================================================
df[df.isnull().values==True]可以只显示存在缺失值的行列，清楚的确定缺失值的位置。
https://www.cnblogs.com/chaosimple/p/4153083.html
obj = Series([7,-5,7,4,2,0,4])
#而numpy中的argsort函数比较奇怪，返回的是把数据进行排序之后，按照值得顺序对应的下标，下标从0开始
print np.argsort(obj)
 #打印结果为：1,5,4,3,6,0,2 
 
=================================================================================

>>> q
    a  b  c
s1  0  1  2
s2  3  4  5

>>> q.stack()
s1  a    0
    b    1
    c    2
s2  a    3
    b    4
    c    5
dtype: int32

>>> q.stack().index
MultiIndex(levels=[['s1', 's2'], ['a', 'b', 'c']],
           labels=[[0, 0, 0, 1, 1, 1], [0, 1, 2, 0, 1, 2]])

>>> q.unstack()
a  s1    0
   s2    3
b  s1    1
   s2    4
c  s1    2
   s2    5
dtype: int32

>>> q.unstack().index
MultiIndex(levels=[['a', 'b', 'c'], ['s1', 's2']],
           labels=[[0, 0, 1, 1, 2, 2], [0, 1, 0, 1, 0, 1]])
           
stack将columns转为index，unstack将index转成columns并作为index，相当于转置后stack，
即q.T.stack()==q.unstack()   ，   q.T.unstack()==q.stack()

=================================================================================

将q转换成p，p和q的数据如下：
>>> q
    a0  a1  a2  a3  a4
0  001  90  01  语文  张三
1  002  96  01  语文  李四
2  003  93  01  语文  王五
3  001  87  02  数学  张三
4  002  82  02  数学  李四
5  003  80  02  数学  王五
>>>p
  userNum userName  score_01  rank_01  score_02  rank_02
0   001       张三      90        3        87        1
1   002       李四      96        1        82        2
2   003       王五      93        2        80        3

步骤如下：
#第一步创建透析表，将a0做index，a2做columns，值取a1
>>> p1=q.pivot(index='a0',columns='a2',values='a1')
>>> p1
a2   01  02
a0         
001  90  87
002  96  82
003  93  80

#第二部将p1和p1的排序连接起来
>>> p2=pd.concat([p1,p1.rank(ascending=0)],axis=1)
#修改columns的title（？）
>>> p2.columns=['score_01','score_02','rank_01','rank_02']
#删除index的name
>>> p2.index.name=None
>>> p2
    score_01 score_02  rank_01  rank_02
001       90       87      3.0      1.0
002       96       82      1.0      2.0
003       93       80      2.0      3.0

#第三部，删除原来'rank_01'的列，将它插入成第1列，目的是交换列
>>> p2.insert(1,'rank_01',p2.pop('rank_01'))
>>> p2
    score_01  rank_01 score_02  rank_02
001       90      3.0       87      1.0
002       96      1.0       82      2.0
003       93      2.0       80      3.0

#取原数据q的学生名字，这里为了不重复取用了    ：2    ，这种方法肯定不好
更好的写法是p3.drop_duplicates('a4','first',inplace=True)进行原地删除重复项
>>> p3=q.loc[:2,['a0','a4']]
#重命名列的title，用了另一种方法
>>> p3.rename(columns={'a4':'userName'},inplace=True)
>>> p3
    a0 userName
0  001       张三
1  002       李四
2  003       王五

#按学生编号连接姓名和成绩
#这里写p2.join(p3)更好，因为merge相当于对匹配项进行笛卡尔乘积，join直接按index进行匹配，类似vlookup
>>> p4=p2.merge(p3,left_index=True,right_on='a0')
#交换列
>>> p4.insert(0,'userNum',p4.pop('a0'))
#将名次的数据类型从float转int
>>> p4.iloc[:,[2,4]]=p4.iloc[:,[2,4]].applymap(int)
>>> p4
  userNum score_01  rank_01 score_02  rank_02 userName
0     001       90        3       87        1       张三
1     002       96        1       82        2       李四
2     003       93        2       80        3       王五

=================================================================================





